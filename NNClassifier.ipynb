{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.FindFractalFeatures import x_train, y_train, x_test, y_test\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "#img_size = 400\n",
    "N, H, K = x_train.shape[1], 400, 2      # No. of input features (input layer size), hidden layer size, No. of classes (output layer size)\n",
    "num_epochs, batch_size = 2, 100\n",
    "learning_rate = 0.003\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([272, 12])\n",
      "torch.Size([91, 12])\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(x_train, y_train, x_test, y_test):\n",
    "    x_train = torch.Tensor(x_train) # transform to torch tensor\n",
    "    y_train = torch.Tensor(y_train) # transform to torch tensor\n",
    "    y_train = y_train.type(torch.LongTensor)\n",
    "    x_test = torch.Tensor(x_test) # transform to torch tensor\n",
    "    y_test = torch.Tensor(y_test) # transform to torch tensor\n",
    "    y_test = y_test.type(torch.LongTensor)\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "    # Data loader: now they are converted to batches of [batch_size, 1, P, P]\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = prepare_dataset(x_train, y_train, x_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, N, H, K):                    # Give the model the no. of neurons in the input, hidden and output layers\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        self.netLayers= nn.Sequential(\n",
    "        nn.Linear(N, H), nn.ReLU(),                 # First hidden Layer             \n",
    "        nn.Linear(H, K)                             # Output Layer\n",
    "        )\n",
    "\n",
    "        self.N = N\n",
    "        # Loss and optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()      # Loss function\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)  # To minimize loss\n",
    "       \n",
    "    def forward(self, x):\n",
    "        logits = self.netLayers(x)\n",
    "        return logits\n",
    "\n",
    "    def train(self, num_epochs, train_loader):\n",
    "        for epoch in range(num_epochs):\n",
    "            for  (features, labels) in tqdm(train_loader):  #each batch is a tuple of features and their corresponding labels.\n",
    "                \n",
    "                features = features.to(device)        # from [batch_size, 1, P, P] to [batch_size, P**2]\n",
    "                labels = labels.to(device)                      # [batch_size] : Dataset labels of current batch\n",
    "                \n",
    "                # Forward pass\n",
    "                logits = self(features)                          # Propagate the batch: gives output [batch_size, K] \n",
    "                loss = self.criterion(logits, labels)          # Calculate the loss (uses Softmak on the outputs along the way)\n",
    "                \n",
    "                # Backward Pass\n",
    "                self.optimizer.zero_grad()                     # Clear the gradients for all network parameters (e.g. due to a previous batch)\n",
    "                loss.backward()                                # Accumulate all the gradients due to the current batch\n",
    "                self.optimizer.step()                          # Update the network's weights and biases\n",
    "                \n",
    "        \n",
    "    \n",
    "    def test(self, train_loader):\n",
    "        with torch.no_grad():\n",
    "            n_correct = 0\n",
    "            n_correct_rand = 0\n",
    "            for test_features, test_labels in train_loader:\n",
    "                test_features = test_features.to(device)     # Flattening the image first\n",
    "                test_labels = test_labels.to(device)\n",
    "                logits = self(test_features)                                 # Propagate the test batch\n",
    "                predicted = logits.argmax(1)                    #the highest logit is also the highest softmax probability. This has shape (batch_size,)\n",
    "                n_correct += (predicted == test_labels).sum().item()\n",
    "\n",
    "                random_guess = torch.from_numpy(np.random.randint(0,2,len(predicted)))\n",
    "                n_correct_rand += (random_guess == test_labels).sum().item()\n",
    "\n",
    "            acc = 100.0 * n_correct / (len(train_loader) * batch_size)\n",
    "            acc_rand = 100.0 * n_correct_rand / (len(train_loader) * batch_size)\n",
    "            print(f'Model Accuracy is at {acc} and Random Guessing Accuracy is at {acc_rand} %')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(handwriting, saved=False):\n",
    "    model = NeuralNet(N, H, K).to(device)      #so it's done on the GPU if available.\n",
    "\n",
    "    # Load or Train the model\n",
    "    if saved:\n",
    "        model.load_state_dict(torch.load('./Intelligence/GenderIntelligence.pth'))\n",
    "    else:\n",
    "        train_loader, test_loader = prepare_dataset(x_train, y_train, x_test, y_test)                            # Prepare dataset\n",
    "        model.train(num_epochs, train_loader)                                    # Train the model\n",
    "        model.test(test_loader)                                                  # Test the model\n",
    "        torch.save(model.state_dict(), './Intelligence/GenderIntelligence.pth')\n",
    "\n",
    "    if(handwriting):\n",
    "       pass\n",
    "    return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([272, 12])\n",
      "torch.Size([91, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 485.75it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 422.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is at 54.0 and Random Guessing Accuracy is at 48.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_gender('');"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
