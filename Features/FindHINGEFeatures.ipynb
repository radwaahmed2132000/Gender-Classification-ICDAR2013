{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import cv2\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_ANGLE_BINS = 40\n",
    "BIN_SIZE = 360 // N_ANGLE_BINS\n",
    "LEG_LENGTH = 25\n",
    "np.seterr(divide = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../Preprocessing/Read_Data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hinge_feature(image):\n",
    "\timage = cv2.medianBlur(image, 3)\n",
    "\tbw_image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\tcontours, _= cv2.findContours(\n",
    "\t\t\t\tbw_image, cv2.RETR_TREE, \n",
    "\t\t\t\tcv2.CHAIN_APPROX_NONE\n",
    "\t\t\t\t)\n",
    "\tcontours = sorted(contours, key=cv2.contourArea, reverse=True)[1:]\n",
    "\t\n",
    "\thist = np.zeros((N_ANGLE_BINS, N_ANGLE_BINS))\n",
    "\tfor cnt in contours:\n",
    "\t\tn_pixels = len(cnt)\n",
    "\t\tif n_pixels <= LEG_LENGTH:\n",
    "\t\t\tcontinue\n",
    "\t\t\n",
    "\t\tpoints = np.array([point[0] for point in cnt])\n",
    "\t\txs, ys = points[:, 0], points[:, 1]\n",
    "\t\tpoint_1s = np.array([cnt[(i + LEG_LENGTH) % n_pixels][0] for i in range(n_pixels)])\n",
    "\t\tpoint_2s = np.array([cnt[(i - LEG_LENGTH) % n_pixels][0] for i in range(n_pixels)])\n",
    "\t\tx1s, y1s = point_1s[:, 0], point_1s[:, 1]\n",
    "\t\tx2s, y2s = point_2s[:, 0], point_2s[:, 1]\n",
    "\t\t\n",
    "\t\tphi_1s = np.degrees(np.arctan2(y1s - ys, x1s - xs) + np.pi)\n",
    "\t\tphi_2s = np.degrees(np.arctan2(y2s - ys, x2s - xs) + np.pi)\n",
    "\t\t\n",
    "\t\tindices = np.where(phi_2s > phi_1s)[0]\n",
    "\t\t\n",
    "\t\tfor i in indices:\n",
    "\t\t\tphi1 = int(phi_1s[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "\t\t\tphi2 = int(phi_2s[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "\t\t\thist[phi1, phi2] += 1\n",
    "\t\t\t\n",
    "\tnormalised_hist = hist / np.sum(hist)\n",
    "\tfeature_vector = normalised_hist[np.triu_indices_from(normalised_hist, k = 1)]\n",
    "\t\n",
    "\treturn feature_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 37/271 [00:06<00:40,  5.75it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000004?line=0'>1</a>\u001b[0m x_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([get_hinge_feature((img)) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m tqdm(x_train)])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000004?line=1'>2</a>\u001b[0m x_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([get_hinge_feature((img)) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m tqdm(x_test)])\n",
      "\u001b[1;32m/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb Cell 5'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000004?line=0'>1</a>\u001b[0m x_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([get_hinge_feature((img)) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m tqdm(x_train)])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000004?line=1'>2</a>\u001b[0m x_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([get_hinge_feature((img)) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m tqdm(x_test)])\n",
      "\u001b[1;32m/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb Cell 4'\u001b[0m in \u001b[0;36mget_hinge_feature\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=16'>17</a>\u001b[0m points \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([point[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m point \u001b[39min\u001b[39;00m cnt])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=17'>18</a>\u001b[0m xs, ys \u001b[39m=\u001b[39m points[:, \u001b[39m0\u001b[39m], points[:, \u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=18'>19</a>\u001b[0m point_1s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([cnt[(i \u001b[39m+\u001b[39m LEG_LENGTH) \u001b[39m%\u001b[39m n_pixels][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_pixels)])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=19'>20</a>\u001b[0m point_2s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([cnt[(i \u001b[39m-\u001b[39m LEG_LENGTH) \u001b[39m%\u001b[39m n_pixels][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_pixels)])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=20'>21</a>\u001b[0m x1s, y1s \u001b[39m=\u001b[39m point_1s[:, \u001b[39m0\u001b[39m], point_1s[:, \u001b[39m1\u001b[39m]\n",
      "\u001b[1;32m/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb Cell 4'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=16'>17</a>\u001b[0m points \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([point[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m point \u001b[39min\u001b[39;00m cnt])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=17'>18</a>\u001b[0m xs, ys \u001b[39m=\u001b[39m points[:, \u001b[39m0\u001b[39m], points[:, \u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=18'>19</a>\u001b[0m point_1s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([cnt[(i \u001b[39m+\u001b[39;49m LEG_LENGTH) \u001b[39m%\u001b[39;49m n_pixels][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_pixels)])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=19'>20</a>\u001b[0m point_2s \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([cnt[(i \u001b[39m-\u001b[39m LEG_LENGTH) \u001b[39m%\u001b[39m n_pixels][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_pixels)])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/essam/Documents/GitHub/Gender-Classification-ICDAR2013/Features/FindHINGEFeatures.ipynb#ch0000003?line=20'>21</a>\u001b[0m x1s, y1s \u001b[39m=\u001b[39m point_1s[:, \u001b[39m0\u001b[39m], point_1s[:, \u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train = np.array([get_hinge_feature((img)) for img in tqdm(x_train)])\n",
    "x_test = np.array([get_hinge_feature((img)) for img in tqdm(x_test)])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
